{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alkhey130/Agentimobilier/blob/main/miniPROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20a79db2",
      "metadata": {
        "id": "20a79db2",
        "outputId": "817f711f-fa59-455d-cfb4-cb2fe06595ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.57.3)\n",
            "Requirement already satisfied: peft in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: datasets in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.4.1)\n",
            "Requirement already satisfied: accelerate in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.12.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.3.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\ali\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\ali\\appdata\\roaming\\python\\python313\\site-packages (from peft) (7.1.3)\n",
            "Requirement already satisfied: torch>=1.13.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from peft) (2.9.1)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pandas in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.3.3)\n",
            "Requirement already satisfied: httpx<1.0.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.70.18)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.13.0->peft) (3.6)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: setuptools in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch>=1.13.0->peft) (80.9.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\ali\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ali\\appdata\\roaming\\python\\python313\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ali\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ali\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers peft datasets accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "709257d4",
      "metadata": {
        "id": "709257d4",
        "outputId": "3fbe9d18-10fc-4287-9ef1-e898a44b5b1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 3/3 [00:00<00:00, 21.21 examples/s]\n",
            "c:\\Users\\ALI\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\peft\\tuners\\lora\\layer.py:2285: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n",
            "c:\\Users\\ALI\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:05, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>6.769100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6.658100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from datasets import Dataset\n",
        "\n",
        "# 1) Modèle simple et stable\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# 2) Petit dataset \"service client\"\n",
        "data = [\n",
        "    {\"text\": \"Client: Bonjour, j'ai un problème avec ma commande.\\nAgent: Bonjour, pouvez-vous me fournir votre numéro de commande ?\"},\n",
        "    {\"text\": \"Client: Ma livraison est en retard.\\nAgent: Pouvez-vous me donner votre numéro de suivi ?\"},\n",
        "    {\"text\": \"Client: Je veux annuler ma commande.\\nAgent: D’accord, je peux vous aider. Quel est votre numéro de commande ?\"}\n",
        "]\n",
        "\n",
        "dataset = Dataset.from_list(data)\n",
        "\n",
        "def preprocess(example):\n",
        "    tokens = tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
        "    return tokens\n",
        "\n",
        "dataset = dataset.map(preprocess)\n",
        "\n",
        "# 3) Configuration LoRA simple\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=[\"attn.c_attn\", \"attn.c_proj\"],  # Pour GPT-2\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# 4) Entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./sc_lora\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    num_train_epochs=2,\n",
        "    fp16=False,\n",
        "    logging_steps=1,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(\"lora_service_client\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016a289a",
      "metadata": {
        "id": "016a289a",
        "outputId": "2c014d42-dcbb-42ab-a905-2b3415607939"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Client: Bonjour, j’ai bien récu ma commande merci.\n",
            "Agent: Bonjour, j’ai bien récu ma commande merci.\n",
            "Agent: Bonjour, j’ai bien récu ma commande merci.\n",
            "Agent: Bonjour, j’ai bien récu ma commande merci.\n",
            "Agent: Bonjour, j’ai bien récu ma commande merci.\n",
            "Agent: Bonjour, j’ai bien récu ma commande merci.\n",
            "Agent: Bonjour, j’ai bien récu ma commande merci.\n",
            "Agent: Bonjour, j’ai bien récu ma commande merci.\n",
            "Agent: Bonjour, j’ai bien récu ma commande merci.\n",
            "Agent: Bonjour, j’ai b\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "base = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "model = PeftModel.from_pretrained(base, \"lora_service_client\")\n",
        "\n",
        "prompt = \"Client: Bonjour, j’ai bien récu ma commande merci.\\nAgent:\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs, max_length=200)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}